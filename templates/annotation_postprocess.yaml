entrypoint: main
arguments:
    parameters:
    - name: "source"
      value: https://github.com/onepanelio/cvat-training.git
    
    - name: "input-video"
      value: "raw-input/2020703/20200703_132826.mp4"
    
    - name: "output-path"
      value: "processed_output/20200703_132826/"
    
    - name: "object-detection-model-path"
      value: "datasets/crb/CVAT-5-CLASSES/models/frcnn-res101-coco_e70000_12_17_2_19_20_07142020170567/frozen_inference_graph.pb"
    
    - name: "object-detection-confidence-threshold"
      value: 0.5
  
    - name: "v-shape-detection-model-path"
      value: "datasets/crb/CVAT-SEGMENTATION/models/multi_maskrcnn_07182020212833/logs/cvat20200718T1746/mask_rcnn_cvat_0160.h5"
    
    - name: "v-shape-detection-model-confidence-threshold"
      value: 0.5

    # path to csv file which has classes same as the task in CVAT you want to use (optional)
    - name: "classes-csv-path"
      value: "datasets/crb/CVAT-5-CLASSES/models/frcnn-res101-coco_e70000_12_17_2_19_20_07142020170567/classes.csv"
    
    - name: "classes-csv-type"
      value: "od"

    # task id of CVAT task you want to use, required only if you want to upload XML into CVAT
    # you can always manually change it
    - name: "cvat-task-id"
      value: 1

    - name: "cvat-task-name"
      value: "demo"

    - name: "type"
      value: "both"

    - displayName: Node pool
      hint: Name of node pool or group
      type: select.select
      name: sys-node-pool
      value: Standard_NC6
      required: true
      options:
      - name: "CPU: 2, RAM: 8GB"
        value: Standard_D2s_v3
      - name: "CPU: 4, RAM: 16GB"
        value: Standard_D4s_v3
      - name: "GPU: 1xV100, CPU: 6, RAM: 56GB"
        value: Standard_NC6
    
    - name: tf-image
      value: tensorflow/tensorflow:1.13.1-gpu-py3
    
    - name: gps-csv-path
      value: "raw-input/20200703/20200703_132826_gps.csv"

volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 50Gi
  - metadata:
      name: output
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 50Gi
templates:
  - name: main
    dag:
      tasks:
      - name: process-video
        template: video

  - name: video
    inputs:
      artifacts:
      - name: src
        path: /mnt/src/op
        git:
          repo: "{{workflow.parameters.source}}"
          revision: "debug-onepanel"
      - git:
          repo: 'https://github.com/onepanelio/Mask_RCNN.git'
          revision: "no-boto"
        name: msrc
        path: /mnt/src/mask
      - name: data
        path: /mnt/data/datasets/temp.mp4
        s3:
          key: "{{workflow.parameters.input-video}}"
      - name: models
        path: /mnt/data/od-models/frozen_inference_graph.pb
        s3: 
          key: "{{workflow.parameters.object-detection-model-path}}"
      - name: models-mask
        path: /mnt/data/mask-models/mask_rcnn_cvat.h5
        s3:
          key: "{{workflow.parameters.v-shape-detection-model-path}}"
      
      - name: models-csv
        path: /mnt/data/datasets/classes.csv
        s3:
          key: "{{workflow.parameters.classes-csv-path}}"
      
      - name: gps-csv
        path: /mnt/data/datasets/gps.csv
        s3:
          key: "{{workflow.parameters.gps-csv-path}}"
          
        optional: true

    outputs:
      artifacts:
      - name: output
        path: /mnt/output
        optional: true
        s3:
            key: "{{workflow.parameters.output-path}}"
    container:

      image: "{{workflow.parameters.tf-image}}"
      command: [sh,-c]
      args:
        - |
          apt-get update && \
          apt-get install -y python3-pip libglib2.0-0 libsm6 libxext6 libxrender-dev git&& \
          pip install -r /mnt/src/mask/requirements.txt && \
          git clone https://github.com/waleedka/coco && \
          cd coco/PythonAPI && \
          python setup.py build_ext install && \
          rm -rf build && \
          cd /mnt/src/mask/ && \
          python setup.py install && \
          python /mnt/src/op/inference_demo/demo.py  \
                            --type={{workflow.parameters.type}}  \
                            --classes_type={{workflow.parameters.classes-csv-type}}  \
                            --od_threshold={{workflow.parameters.object-detection-confidence-threshold}}  \
                            --mask_threshold={{workflow.parameters.v-shape-detection-model-confidence-threshold}} \
                            --task_id={{workflow.parameters.cvat-task-id}}  \
                            --task_name={{workflow.parameters.cvat-task-name}} 
          
      
      workingDir: /mnt/src
      volumeMounts:
      - name: data
        mountPath: /mnt/data
      - name: output
        mountPath: /mnt/output